{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "notebook.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhuyenLE-maths/Project_Income_Classification/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMX_bYzM1ptP"
      },
      "source": [
        "## Content\n",
        "I. Data preparation\n",
        "\n",
        "II. Data extracting and cleaning\n",
        "- Check the duplicated rows\n",
        "- Missing values\n",
        "- Outliers\n",
        "\n",
        "III. Exploratory data analysis\n",
        "\n",
        "IV. Data preprocessing\n",
        "\n",
        "V. PCA\n",
        "\n",
        "VI. Deploy Machine learning models for classifying data\n",
        " \n",
        " ---------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YnNG4gT1WBB"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pyVcBLgLXyM"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Competitions/Income_classification/')\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM7Lu49C1XY3"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from termcolor import colored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EDK8TeU2khb"
      },
      "source": [
        "## I. Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp7b6UH31Xa5"
      },
      "source": [
        "data_path = 'Dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPoYR6E51XdS"
      },
      "source": [
        "os.listdir(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ0zRwcg1XiO"
      },
      "source": [
        "df_train = pd.read_csv(data_path + 'train.csv.zip')\n",
        "df_test = pd.read_csv(data_path + 'test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNT4VnOX1XlD"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_J50KMI1Xnr"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXS93HCj3vSV"
      },
      "source": [
        "print('Train shape:', df_train.shape)\n",
        "print('Test shape', df_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uox-3QVE3htz"
      },
      "source": [
        "## II. Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iktP-F73-vM"
      },
      "source": [
        "### 1. Check the duplicated rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U03VaAA_1XqM"
      },
      "source": [
        "df_train[df_train.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjzpbn53-Ak"
      },
      "source": [
        "df_test[df_test.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM2-K8ya4N8s"
      },
      "source": [
        "**There is no dupplicated row in both training and test sets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMruPYbn4WE2"
      },
      "source": [
        "### 2. Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0s6839X3-Cz"
      },
      "source": [
        "df_train.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S92ImE23-FF"
      },
      "source": [
        "df_test.isna().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoDCcNRxLVSZ"
      },
      "source": [
        "Our dataset is completely clean. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3gEUuAs49jT"
      },
      "source": [
        "### III. Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3DDOfDW5A_7"
      },
      "source": [
        "### 1. Types of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n__k7LdF3-He"
      },
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "df_train.dtypes.value_counts().plot.pie()\n",
        "plt.title('Distribution of data types')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUWanzw95ePw"
      },
      "source": [
        "### 2. Target column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0xlxQ683-J8"
      },
      "source": [
        "plt.figure(figsize = (6,5))\n",
        "df_train['target_income'].value_counts().plot.bar()\n",
        "plt.title('Income distribution')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rta8CF0m64AY"
      },
      "source": [
        "## 3. Visualize other columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLQCwbdT5icy"
      },
      "source": [
        "Cols = list(df_train.columns)\n",
        "Cols.remove('target_income')\n",
        "Cols.remove('ID')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcGvlT5HS0Mp"
      },
      "source": [
        "Cols_visu = ['work_type', 'education', 'total_education_yrs', 'marital_state', 'job', 'status', 'ethnicity', 'sex', 'hrs_per_week']\n",
        "\n",
        "for col in Cols_visu:\n",
        "    \n",
        "    if col == 'hrs_per_week':\n",
        "        plt.figure(figsize = (18, 5))\n",
        "        \n",
        "    df_train[col].value_counts().plot.bar()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_j6P1MdXy-A"
      },
      "source": [
        "### Visualize the distribution of target in each category"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSUyxiPZLVSb"
      },
      "source": [
        "**Income by work type**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar3Rq5-DXtTR"
      },
      "source": [
        "group_work_type = df_train.groupby(['work_type', 'target_income'])\n",
        "group_work_type_df = group_work_type.size().unstack()\n",
        "group_work_type_df.plot(kind = 'barh', figsize = (10,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAHcDXfAYm7t"
      },
      "source": [
        "**Income by education**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNN34pYQYm9z"
      },
      "source": [
        "group_edu = df_train.groupby(['education', 'target_income'])\n",
        "group_edu_df = group_edu.size().unstack()\n",
        "group_edu_df.plot(kind = 'barh', figsize = (10,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pWqO0KNLVSc"
      },
      "source": [
        "***This figure shows the higher education you have, the better income you get. The probability to get high income when you just finish 9th class is very small.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYgmXY9KYnEA"
      },
      "source": [
        "**Income by merital state**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a37jjnu3LVSc"
      },
      "source": [
        "group_mari = df_train.groupby(['marital_state', 'target_income'])\n",
        "group_mari_df = group_mari.size().unstack()\n",
        "group_mari_df.plot(kind = 'barh', figsize = (8,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz8I6BhSLVSc"
      },
      "source": [
        "***Wow!!! Very suprise! The proportion of group 1 (income > 50k) in the group \"Married-civ-spouse\" is much larger than in other groups. So, you want to get better income, you should get married first, :v*** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRQRHfnqLVSc"
      },
      "source": [
        "**Income by status**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0AOiQ7ULVSc"
      },
      "source": [
        "group_status = df_train.groupby(['status', 'target_income'])\n",
        "group_status_df = group_status.size().unstack()\n",
        "group_status_df.plot(kind = 'barh', figsize = (8,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X04KsyP5LVSd"
      },
      "source": [
        "**Income by job**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7uC6zQ-oLVSd"
      },
      "source": [
        "group_jobs = df_train.groupby(['job', 'target_income'])\n",
        "group_jobs_df = group_jobs.size().unstack()\n",
        "group_jobs_df.plot(kind = 'barh', figsize = (10,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExeNjj0kLVSd"
      },
      "source": [
        "**Income by ethnicity**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmFotpluLVSd"
      },
      "source": [
        "group_eth = df_train.groupby(['ethnicity', 'target_income'])\n",
        "group_eth_df = group_eth.size().unstack()\n",
        "group_eth_df.plot(kind = 'bar', figsize = (8,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oINUIa-jLVSd"
      },
      "source": [
        "**Income by sex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3smyKpnLVSd"
      },
      "source": [
        "group_s = df_train.groupby(['sex', 'target_income'])\n",
        "group_s_df = group_s.size().unstack()\n",
        "group_s_df.plot(kind = 'bar', figsize = (8,6))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_MX1UlQLVSd"
      },
      "source": [
        "**Correlation between variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agRELP70LVSd"
      },
      "source": [
        "plt.figure(figsize = (8,8))\n",
        "sns.heatmap(df_train.corr(), square = True, annot = False)\n",
        "plt\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnd-dOQpLVSd"
      },
      "source": [
        "**From this figure, we can see that the income is highly correlated to some variables as \"age\", \"total_education_yrs\". The correlations between income and \"final_weight\", \"job\", \"ethnicity\", \"nationality\" are nearly zeros.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkKkLnJyVmJ1"
      },
      "source": [
        "## IV. Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdFkP6brVvw5"
      },
      "source": [
        "###  Encoding some categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuUSG0L_LVSe"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rApIptAQVluE"
      },
      "source": [
        "Cols_encode = ['work_type', 'education', 'marital_state', 'job', 'status', 'ethnicity', 'sex', 'nationality']\n",
        "\n",
        "for col in Cols_encode:\n",
        "    le = LabelEncoder()\n",
        "    df_train[col] = le.fit_transform(df_train[col])\n",
        "    df_test[col] = le.transform(df_test[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmMbrW5RYmKd",
        "scrolled": true
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UToKcSbLVSe"
      },
      "source": [
        "X_train = df_train.drop(['ID', 'target_income'], axis = 1).values\n",
        "y_train = df_train['target_income']\n",
        "\n",
        "X_test = df_test.drop('ID', axis = 1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRgryNOZLVSe"
      },
      "source": [
        "print('Train shape', X_train.shape)\n",
        "print('Test shape', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds3cXddOLVSe"
      },
      "source": [
        "## V. PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VvXJHALVSe"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from pca_plot_tools import display_explained_var_ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P44qYYiZLVSf"
      },
      "source": [
        "**Data normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tCnVkU5LVSf"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwu75SiALVSf"
      },
      "source": [
        "pca = PCA().fit(X_train_std)\n",
        "\n",
        "var_ratio = pca.explained_variance_ratio_*100\n",
        "display_explained_var_ratio(var_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZLZYT4BLVSf"
      },
      "source": [
        "## VI. Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPpghwMqLVSf"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score \n",
        "\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvNoR4IGLVSf"
      },
      "source": [
        "#from classif_tools import save_classif\n",
        "\n",
        "rst_path = os.getcwd() + '/' + 'Classif_rst/'\n",
        "#os.mkdir(rst_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXXHsgfKLVSf"
      },
      "source": [
        "### Data preparation for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTokjuhSLVSf"
      },
      "source": [
        "X0 = X_train[np.where(y_train == 0)]\n",
        "X1 = X_train[np.where(y_train == 1)]\n",
        "\n",
        "y0 = np.zeros(X0.shape[0])\n",
        "y1 = np.ones(X1.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRnWvdszLVSf"
      },
      "source": [
        "**Train/val splitting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLwrTvmFLVSf"
      },
      "source": [
        "t_size = 0.25\n",
        "rand_state = 12\n",
        "\n",
        "X0_train, X0_val, y0_train, y0_val = train_test_split(X0, y0, test_size = t_size, random_state = rand_state)\n",
        "X1_train, X1_val, y1_train, y1_val = train_test_split(X1, y1, test_size = t_size, random_state = rand_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZrNVijewyXo"
      },
      "source": [
        "X0_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPyZ-Ae6w1j4"
      },
      "source": [
        "X1_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebcvy__SLVSf"
      },
      "source": [
        "X_train = np.concatenate((X0_train, X1_train))\n",
        "X_val = np.concatenate((X0_val, X1_val))\n",
        "\n",
        "y_train = np.concatenate((y0_train, y1_train))\n",
        "y_val = np.concatenate((y0_val, y1_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AIHQnoJLVSf"
      },
      "source": [
        "**Data balancing for training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVKnWb0NLVSf"
      },
      "source": [
        "over_sampler = SMOTE(random_state = rand_state)\n",
        "X_train, y_train = over_sampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1q7xJBVLVSg"
      },
      "source": [
        "**Data normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8n4fnY6LVSg"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9HftRc9LVSg"
      },
      "source": [
        "val_info = {}\n",
        "val_info['y_val'] = y_val\n",
        "\n",
        "np.save(rst_path + 'val_info.npy', val_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RWKSOTTLVSg"
      },
      "source": [
        "### 1. Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvmpQymBLVSg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "param_grid_LR = {'C': [1, 2, 3]}\n",
        "model_LR = LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE_PAf0ULVSg"
      },
      "source": [
        "grid_search_LR = GridSearchCV(estimator = model_LR(),\n",
        "                             param_grid = param_grid_LR, \n",
        "                             cv = 5, \n",
        "                             verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLGND8ziLVSg"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_LR.fit(X_train_scaled, y_train)\n",
        "y_pred_LR = grid_search_LR.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0\n",
        "\n",
        "rst_LR = {}\n",
        "rst_LR['y_pred_LR'] = y_pred_LR\n",
        "rst_LR['best_score'] = grid_search_LR.best_score_\n",
        "rst_LR['best_params'] = grid_search_LR.best_params_\n",
        "rst_LR['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_LR.npy', rst_LR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQqzUHaALVSg"
      },
      "source": [
        "### 2. Support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSbFMjpzLVSg"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "param_grid_SVM = [{'C': [5, 10, 20, 40], 'kernel': ['rbf']}]\n",
        "model_SVM = SVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eYDDwwfLVSg"
      },
      "source": [
        "grid_search_SVM = GridSearchCV(estimator = model_SVM(),\n",
        "                           param_grid = param_grid_SVM,\n",
        "                           cv = 5,\n",
        "                           verbose = 1\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLpYGAX-5iho"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_SVM.fit(X_train_scaled, y_train)\n",
        "y_pred_SVM = grid_search_SVM.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0\n",
        "\n",
        "rst_SVM = {}\n",
        "rst_SVM['y_pred_SVM'] = y_pred_SVM\n",
        "rst_SVM['best_score'] = grid_search_SVM.best_score_\n",
        "rst_SVM['best_params'] = grid_search_SVM.best_params_\n",
        "rst_SVM['time'] = t\n",
        "np.save(rst_path + 'rst_SVM.npy', rst_SVM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab3Xght2LVSg"
      },
      "source": [
        "### 3. K-nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUK7VFj9LVSg"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "param_grid_knn = {'n_neighbors' : [6, 8, 10, 12]}\n",
        "model_knn = KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8CTSmqsLVSh"
      },
      "source": [
        "grid_search_knn = GridSearchCV(estimator = model_knn(),\n",
        "                              param_grid = param_grid_knn, \n",
        "                              cv = 5, \n",
        "                              verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwl3PQ3VLVSh"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_knn.fit(X_train_scaled, y_train)\n",
        "y_pred_knn = grid_search_knn.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0\n",
        "\n",
        "rst_knn = {}\n",
        "rst_knn['y_pred_knn'] = y_pred_knn\n",
        "rst_knn['best_score'] = grid_search_knn.best_score_\n",
        "rst_knn['best_params'] = grid_search_knn.best_params_\n",
        "rst_knn['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_knn.npy', rst_knn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4zXqPp1LVSh"
      },
      "source": [
        "### 4. Linear Discriminant Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugHqR7Z_LVSh"
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "param_grid_LDA = {}\n",
        "model_LDA = LinearDiscriminantAnalysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL34Q31wLVSh"
      },
      "source": [
        "grid_search_LDA = GridSearchCV(estimator = model_LDA(), \n",
        "                               param_grid = param_grid_LDA, \n",
        "                               cv = 5, \n",
        "                               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftR6UlnbLVSh"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_LDA.fit(X_train_scaled, y_train)\n",
        "y_pred_LDA = grid_search_LDA.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0\n",
        "\n",
        "rst_LDA = {}\n",
        "rst_LDA['y_pred_LDA'] = y_pred_LDA\n",
        "rst_LDA['best_score'] = grid_search_LDA.best_score_\n",
        "rst_LDA['best_params'] = grid_search_LDA.best_params_\n",
        "rst_LDA['time'] = t\n",
        "\n",
        "np.save(rst_path + 'rst_LDA.npy', rst_LDA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCwEUdI4LVSh"
      },
      "source": [
        "### 5. Decision tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGwau7_3LVSh"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "param_grid_DT = {'criterion': ['gini', 'entropy']}\n",
        "model_DT = DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzhbBiXQLVSh"
      },
      "source": [
        "grid_search_DT = GridSearchCV(estimator = model_DT(), \n",
        "                              param_grid = param_grid_DT,\n",
        "                              cv = 5, \n",
        "                              verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9qxhNxYLVSh"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_DT.fit(X_train_scaled, y_train)\n",
        "y_pred_DT = grid_search_DT.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0\n",
        "\n",
        "rst_DT = {}\n",
        "rst_DT['y_pred_DT'] = y_pred_DT\n",
        "rst_DT['best_score'] = grid_search_DT.best_score_\n",
        "rst_DT['best_params'] = grid_search_DT.best_params_\n",
        "rst_DT['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_DT.npy', rst_DT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPl6rURBLVSh"
      },
      "source": [
        "### 6. Gaussian Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb5q3VFzLVSh"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "param_grid_NB = {}\n",
        "model_NB = GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNWDC_xaLVSi"
      },
      "source": [
        "grid_search_NB = GridSearchCV(estimator = model_NB(),\n",
        "                              param_grid = param_grid_NB, \n",
        "                              cv = 5, \n",
        "                              verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q3Vd5nNLVSi"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_NB.fit(X_train_scaled, y_train)\n",
        "y_pred_NB = grid_search_NB.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_NB = {}\n",
        "rst_NB['y_pred_NB'] = y_pred_NB\n",
        "rst_NB['best_score'] = grid_search_NB.best_score_\n",
        "rst_NB['best_params'] = grid_search_NB.best_params_\n",
        "rst_NB['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_NB.npy', rst_NB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsfEwomOLVSi"
      },
      "source": [
        "### 7. Stochastic Gradient Descent Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyhdBI07LVSi"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "param_grid_SGD = {\n",
        "    \"penalty\" : ['l2', 'l1', 'elasticnet']\n",
        "}\n",
        "model_SGD = SGDClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5BI6lGRLVSi"
      },
      "source": [
        "grid_search_SGD = GridSearchCV(estimator = model_SGD(),\n",
        "                               param_grid = param_grid_SGD,\n",
        "                               cv = 5, \n",
        "                               verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiejBBCRLVSi"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_SGD.fit(X_train_scaled, y_train)\n",
        "y_pred_SGD = grid_search_SGD.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_SGD = {}\n",
        "rst_SGD['y_pred_SGD'] = y_pred_SGD\n",
        "rst_SGD['best_score'] = grid_search_SGD.best_score_\n",
        "rst_SGD['best_params'] = grid_search_SGD.best_params_\n",
        "rst_SGD['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_SGD.npy', rst_SGD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B37LOTmhLVSi"
      },
      "source": [
        "### 8. Random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3b10xgQLVSj"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "param_grid_RF = {\n",
        "    \"criterion\": ['gini', 'entropy']\n",
        "}\n",
        "model_RF = RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVH1GHQLVSj"
      },
      "source": [
        "grid_search_RF = GridSearchCV(estimator = model_RF(),\n",
        "                              param_grid = param_grid_RF,\n",
        "                              cv = 5, \n",
        "                              verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml4wY446LVSj"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_RF.fit(X_train_scaled, y_train)\n",
        "y_pred_RF = grid_search_RF.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_RF = {}\n",
        "rst_RF['y_pred_RF'] = y_pred_RF\n",
        "rst_RF['best_score'] = grid_search_RF.best_score_\n",
        "rst_RF['best_params'] = grid_search_RF.best_params_\n",
        "rst_RF['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_RF.npy', rst_RF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRSCYFaZLVSj"
      },
      "source": [
        "### 9. Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZQUtLs5LVSj"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "param_grid_GBC = {}\n",
        "model_GBC = GradientBoostingClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtNrnTtULVSj"
      },
      "source": [
        "grid_search_GBC = GridSearchCV(estimator = model_GBC(),\n",
        "                               param_grid = param_grid_GBC, \n",
        "                               cv = 5, \n",
        "                               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uJPkGogLVSj"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_GBC.fit(X_train_scaled, y_train)\n",
        "y_pred_GBC = grid_search_GBC.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_GBC = {}\n",
        "rst_GBC['y_pred_GBC'] = y_pred_GBC\n",
        "rst_GBC['best_score'] = grid_search_GBC.best_score_\n",
        "rst_GBC['best_params'] = grid_search_GBC.best_params_\n",
        "rst_GBC['time'] = t \n",
        "np.save(rst_path + 'rst_GBC.npy', rst_GBC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNCHxsk5LVSj"
      },
      "source": [
        "### 10. AdaBoost "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wff5c93ALVSj"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "param_grid_Ada = {}\n",
        "model_Ada = AdaBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7CmJ18rLVSj"
      },
      "source": [
        "grid_search_Ada = GridSearchCV(estimator = model_Ada(),\n",
        "                               param_grid = param_grid_Ada,\n",
        "                               cv = 5, \n",
        "                               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEYQS1-0LVSj"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_Ada.fit(X_train_scaled, y_train)\n",
        "y_pred_Ada = grid_search_Ada.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_Ada = {}\n",
        "rst_Ada['y_pred_Ada'] = y_pred_Ada\n",
        "rst_Ada['best_score'] = grid_search_Ada.best_score_\n",
        "rst_Ada['best_params'] = grid_search_Ada.best_params_\n",
        "rst_Ada['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_Ada.npy', rst_Ada)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GxHPrwiLVSj"
      },
      "source": [
        "### 11. XGBoost (Extreme Gradient Boosting)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFGK71w8LVSk"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "param_grid_XGB = {}\n",
        "model_XGB = XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLfMN29KLVSk"
      },
      "source": [
        "grid_search_XGB = GridSearchCV(estimator = model_XGB(),\n",
        "                               param_grid = param_grid_XGB,\n",
        "                               cv = 5, \n",
        "                               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZTC-m_TLVSk"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_XGB.fit(X_train_scaled, y_train)\n",
        "y_pred_XGB = grid_search_XGB.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_XGB = {}\n",
        "rst_XGB['y_pred_XGB'] = y_pred_XGB\n",
        "rst_XGB['best_score'] = grid_search_XGB.best_score_\n",
        "rst_XGB['best_params'] = grid_search_XGB.best_params_\n",
        "rst_XGB['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_XGB.npy', rst_XGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUhhGSSkLVSk"
      },
      "source": [
        "### 12. Histogram-based gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS7I_XrBLVSk"
      },
      "source": [
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "model_HGB = HistGradientBoostingClassifier\n",
        "param_grid_HGB = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awIanyfFLVSk"
      },
      "source": [
        "grid_search_HGB = GridSearchCV(estimator = model_HGB(),\n",
        "                               param_grid = param_grid_HGB,\n",
        "                               cv = 5, \n",
        "                               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RoPSFu0LVSk"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_HGB.fit(X_train_scaled, y_train)\n",
        "y_pred_HGB = grid_search_HGB.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_HGB = {}\n",
        "rst_HGB['y_pred_HGB'] = y_pred_HGB\n",
        "rst_HGB['best_score'] = grid_search_HGB.best_score_\n",
        "rst_HGB['best_params'] = grid_search_HGB.best_params_\n",
        "rst_HGB['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_HGB.npy', rst_HGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04ohCRgbLVSk"
      },
      "source": [
        "### 13. LightBoosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ell8OBUzLVSk"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "model_LGBM = LGBMClassifier\n",
        "param_grid_LGBM = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6hxONbNLVSk"
      },
      "source": [
        "grid_search_LGBM = GridSearchCV(estimator = model_LGBM(),\n",
        "                                param_grid = param_grid_LGBM,\n",
        "                                cv = 5,\n",
        "                                verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zimxcbcMLVSk"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_LGBM.fit(X_train_scaled, y_train)\n",
        "y_pred_LGBM = grid_search_LGBM.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_LGBM = {}\n",
        "rst_LGBM['y_pred_LGBM'] = y_pred_LGBM\n",
        "rst_LGBM['best_score'] = grid_search_LGBM.best_score_\n",
        "rst_LGBM['best_params'] = grid_search_LGBM.best_params_\n",
        "rst_LGBM['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_LGBM.npy', rst_LGBM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM41D4uALVSl"
      },
      "source": [
        "### 14. CatBoost Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHxUfPubrA5Y"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EI5ImLODLVSl"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "param_grid_Cat = {}\n",
        "model_Cat = CatBoostClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM60glIjLVSl"
      },
      "source": [
        "grid_search_Cat = GridSearchCV(estimator = model_Cat(),\n",
        "                               param_grid = param_grid_Cat,\n",
        "                               cv = 5,\n",
        "                               verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB-lTojgLVSl"
      },
      "source": [
        "t0 = timeit.default_timer()\n",
        "grid_search_Cat.fit(X_train_scaled, y_train)\n",
        "y_pred_Cat = grid_search_Cat.predict(X_val_scaled)\n",
        "t1 = timeit.default_timer()\n",
        "t = t1 - t0 \n",
        "\n",
        "rst_Cat = {}\n",
        "rst_Cat['y_pred_Cat'] = y_pred_Cat\n",
        "rst_Cat['best_score'] = grid_search_Cat.best_score_\n",
        "rst_Cat['best_params'] = grid_search_Cat.best_params_\n",
        "rst_Cat['time'] = t \n",
        "\n",
        "np.save(rst_path + 'rst_Cat.npy', rst_Cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VihI9GF0kv0"
      },
      "source": [
        "## VII. Compare the classification results of all algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XlKl5xY9spc"
      },
      "source": [
        "Model_names = ['LR', 'SVM', 'knn', 'LDA', 'DT', 'NB', 'SGD', 'RF', 'GBC', 'Ada', 'XGB', 'HGB', 'LGBM', 'Cat']\n",
        "Acc_scores = []\n",
        "B_acc_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for name in Model_names:\n",
        "  rst = np.load(rst_path + 'rst_' + name + '.npy', allow_pickle = True).item()\n",
        "  n = 'y_pred_' + name\n",
        "  y_val_pred = rst[n]\n",
        "  acc = np.round(accuracy_score(y_val, y_val_pred), 3)\n",
        "  b_acc = np.round(balanced_accuracy_score(y_val, y_val_pred), 3)\n",
        "  f1 = np.round(f1_score(y_val, y_val_pred),3)\n",
        "\n",
        "  Acc_scores.append(acc)\n",
        "  B_acc_scores.append(b_acc)\n",
        "  f1_scores.append(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ikyqlan9srp"
      },
      "source": [
        "rst_df = {}\n",
        "rst_df['Models'] = Model_names\n",
        "rst_df['Accuracy score'] = Acc_scores\n",
        "rst_df['Balanced accuracy'] = B_acc_scores\n",
        "rst_df['f1 score'] = f1_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG23HS9d-7wY"
      },
      "source": [
        "rst_df = pd.DataFrame(rst_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWq1lyRI-7yk"
      },
      "source": [
        "rst_df.sort_values(by = 'Accuracy score', ascending= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO4kL5J-EieD"
      },
      "source": [
        "M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyOPifedBryi"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "M = confusion_matrix(y_val, y_pred_Cat)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(M, cmap = plt.cm.Blues)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        c = M[j,i]\n",
        "        ax.text(i, j, str(c), va='center', ha='center')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPHuUjLv_8sY"
      },
      "source": [
        "From this result, we see that CatBoost and LightBoost are the two best algorithms in this case. Their accuracy are 86.3% and 85.9%, respectively. \n",
        "The balanced accuracy is smaller than accuracy score in almost cases (exception for Linear Regression, Schochastic Gradient Descent, Linear Discriminant Analysis). It means that the obsevations tend to be classified to the majority class. We can see that more clearly from the confusion matric obtained by AdaBoost algorithm. The mis-classified proportion of group 1 is 28.51%, which is larger than the one of group 0 (9.02%)."
      ]
    }
  ]
}